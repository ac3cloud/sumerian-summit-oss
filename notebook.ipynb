{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# RPS Model Creation"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Preparing the environment\n\nWe require a corpus of training data to help build our model.\nQuite fortunately for us someone has already created one for us on Kaggle.\n\n[https://www.kaggle.com/alishmanandhar/rock-scissor-paper](https://www.kaggle.com/alishmanandhar/rock-scissor-paper)\n\nA login is required to download this, so we uploaded it to S3 earlier to simplify things.\n\nFirst thing we need to do is download it to our instance and unzip it."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "import boto3\n\nbucket = 'ac3-sumerian-rps-sagemaker'\n\nboto3.resource('s3').Bucket(bucket).download_file('final.zip', 'final.zip')\n\n!unzip -q -o final.zip"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "This is python by default.\nAn ! causes a shell command to run"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "!ls"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "or you could use a bash section instead"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "%%bash\nls -l"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "or even ruby and others!"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "%%ruby\n5.times { puts 'Hello!' }"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "By default SageMaker notebook seem to default to using MXNet for keras. We fix this by moving the config file out of the way.\n\n*NB* OK maybe this isn't needed anymore??"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "!mv ~/.keras/keras.json keras_tensorflow.json"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explore the data\n\nLet's take a look at the training and validation data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "%%bash\n\necho\necho \"What is in final\"\nls final\necho \"=========================\"\necho\ncd final\n\n\necho \"What is in the train dir\"\nls train | head\necho \"=========================\"\necho\n\necho \"What is in the train/c0 dir\"\nls train/c0 | head -5\necho\necho \"=========================\"\necho\n\necho \"How many train files\"\nls -1R train | wc -l\necho \"=========================\"\necho\n\necho \"How many valid files\"\nls -1R valid | wc -l"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Set up python\n\nImport a bunch of libraries we'll need later"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "from keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.applications import MobileNetV2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\n\nimport os"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Do some tuning\n\n### batch_size\n  * 32 seems to work - ML Black magic\n  * Other good values 64 and 128\n  * The bigger the batch size the more memory you need\n  \n### epochs\n  * from testing 20 seems to be more than sufficient to get good results\n  * deminishing returns after that\n  * The more epochs the longer the training takes\n  \n### classes\n  * We have three\n  * Rock, Paper and Scissors"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "batch_size = 32\nepochs = 20\nclasses = 3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the model\n\nWe want to use MobileNet v2 as our model.\nOur input shape is 224, 224, 3\n* width\n* height\n* number of channels\n* We don't include the top layer as we are going to replace it\n\nWe load the **ImageNet** weights as we are going to do tranfer learning\n\nThis will load the model and download the weights."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "conv_base = MobileNetV2(\n    input_shape=(224, 224, 3),\n    weights='imagenet',\n    include_top=False,\n)\nconv_base.trainable = True\nconv_base.summary()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Prepare a new model\n\n**NB:** This is where the black magic starts\n\n* Create a new sequential model\n* Add mobilenet that we loaded in to it\n* Flatten\n  * flatten stuff???\n* Dense\n  * Why 256?\n  * tanh is one option others are rreli, prelu\n* Dense\n  * We want only 3 outputs at the end\n  * sigmoid is a good function softmax is another\n* Print out the summary"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "model = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='tanh')) # relu (maybe rrelu or prelu will solve dying issue) could also use sigmoid or tanh \nmodel.add(layers.Dense(classes, activation='sigmoid')) # try softmax\nmodel.summary()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "* trainable - renables training for the original model\n* We compile the model\n  * RMSprop is an opitimizer function which helps \n  * loss - function to measure the loss\n  * metrics - the ones we care about"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), # Adam?\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Prepare the training data\n* Load in the training data\n* We do lots of permutations on the data to get even more data\n* We also load the validation data in.\n* We do not manipulate it, only load it to a consistent size"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "base_dir = 'final'\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'valid')\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n)\nvalidation_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n)\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical'\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical'\n)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Set up checkpoint\n\nNext we set up a checkpoint.\nThis will save a copy of the model but only if the accuracy is improving."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "outputs": [],
      "source": "filepath=\"rps-keras-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(\n    filepath,\n    monitor='val_acc',\n    verbose=1,\n    save_best_only=True,\n    mode='max'\n)\n\n# TODO: Add earlystop\ncallbacks = [checkpoint]\n\nstep_size_train = train_generator.n // train_generator.batch_size\nstep_size_valid = validation_generator.n // validation_generator.batch_size"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Hammer time\n\nWe now run the model passing it everything we have prepared earlier"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "history = model.fit_generator(\n      train_generator,\n      steps_per_epoch=step_size_train,\n      epochs=epochs,\n      callbacks=callbacks,\n      validation_data=validation_generator,\n      validation_steps=step_size_valid,\n      verbose=2)\nprint('DONE')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## How did we go??\n\nOne of the great things about Notebook us being able to display images and matlab plots inline.\n\nNow we can plot how our training went"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "outputs": [],
      "source": "%matplotlib inline\n\nfrom matplotlib import pyplot as plt\n\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Play with our model\n\nLet's run the model against the validation data and check any bad results"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.image as mpimg\n\ndef load_img(filename):\n    return mpimg.imread(filename)\n\n# Create a generator for prediction\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n \n# Get the filenames from the generator\nfnames = validation_generator.filenames\n \n# Get the ground truth from generator\nground_truth = validation_generator.classes\n \n# Get the label to class mapping from the generator\nlabel2index = validation_generator.class_indices\n \n# Getting the mapping from class index to class label\nidx2label = dict((v,k) for k,v in label2index.items())\n \n# Get the predictions from the model using the generator\npredictions = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\npredicted_classes = np.argmax(predictions,axis=1)\n \nerrors = np.where(predicted_classes != ground_truth)[0]\nprint(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n \n# Show the errors\nfor i in range(len(errors)):\n    pred_class = np.argmax(predictions[errors[i]])\n    pred_label = idx2label[pred_class]\n     \n    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n        fnames[errors[i]].split('/')[0],\n        pred_label,\n        predictions[errors[i]][pred_class])\n     \n    original = load_img('{}/{}'.format(validation_dir,fnames[errors[i]]))\n    plt.figure(figsize=[7,7])\n    plt.axis('off')\n    plt.title(title)\n    plt.imshow(original)\n    plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## What about the training data\n\nLet's do the same"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.image as mpimg\n\ndef load_image(filename):\n    return mpimg.imread('filename')\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n  \n# Get the ground truth from generator\nground_truth = validation_generator.classes\n \n# Get the label to class mapping from the generator\nlabel2index = validation_generator.class_indices\n \n# Getting the mapping from class index to class label\nidx2label = dict((v,k) for k,v in label2index.items())\n \n# Get the predictions from the model using the generator\npredictions = model.predict_generator(train_generator, steps=train_generator.samples/train_generator.batch_size,verbose=1)\npredicted_classes = np.argmax(predictions,axis=1)\n \nerrors = np.where(predicted_classes != ground_truth)[0]\nprint(\"No of errors = {}/{}\".format(len(errors),train_generator.samples))\n \n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "# Show the errors\nfor i in range(len(errors)):\n  pred_class = np.argmax(predictions[errors[i]])\n  pred_label = idx2label[pred_class]\n    \n  title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n    fnames[errors[i]].split('/')[0],\n    pred_label,\n    predictions[errors[i]][pred_class])\n  \n  original = load_img('{}/{}'.format(validation_dir,fnames[errors[i]]))\n  plt.figure(figsize=[7,7])\n  plt.axis('off')\n  plt.title(title)\n  plt.imshow(original)\n  plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## We are done\n\nSave the model and upload everything into S3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "model.save('rps-keras-final.hdf5')\n\n!ls -ltr\n\n## Load libraries again in case we are running things out of order\nimport boto3\nfrom pathlib import Path\n\nbucket = 'ac3-sumerian-rps-sagemaker'\n\npathlist = Path('.').glob('*.hdf5')\nfor path in pathlist:\n     boto3.resource('s3').Bucket(bucket).upload_file(str(path), 'keras/{}'.format(str(path)))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# GO BACK TO YOUR ORIGINAL SCRIPT AND STOP THE NOTEBOOK"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
